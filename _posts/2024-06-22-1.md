---
title: First Meeting
date: 2024-06-22 19:30:00 -0500
background: /assets/image/recording/1.png
tags: [Influence Function]
---

Presenter: [Jiaqi Ma](https://jiaqima.github.io/).

References:
- Giordano, Ryan, William Stephenson, Runjing Liu, Michael Jordan, and Tamara Broderick. “[A Swiss Army Infinitesimal Jackknife.](https://proceedings.mlr.press/v89/giordano19a.html)” In Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics (AISTATS), 2019.
- Koh, Pang Wei, and Percy Liang. “[Understanding Black-Box Predictions via Influence Functions.](https://proceedings.mlr.press/v70/koh17a.html)” In Proceedings of the 34th International Conference on Machine Learning (ICML), 2017.
- Agarwal, Naman, Brian Bullins, and Elad Hazan. “[Second-Order Stochastic Optimization for Machine Learning in Linear Time.](https://www.jmlr.org/papers/v18/16-491.html)” Journal of Machine Learning Research (JMLR), 2017.
- Schioppa, Andrea, Polina Zablotskaia, David Vilar, and Artem Sokolov. “[Scaling up Influence Functions.](https://ojs.aaai.org/index.php/AAAI/article/view/20791)” In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2022.
- Martens, James. “[New Insights and Perspectives on the Natural Gradient Method.](https://www.jmlr.org/papers/v21/17-678.html)” Journal of Machine Learning Research (JMLR), 2020.
- Grosse, Roger, Juhan Bae, Cem Anil, Nelson Elhage, Alex Tamkin, Amirhossein Tajdini, Benoit Steiner, et al. “[Studying Large Language Model Generalization with Influence Functions.](http://arxiv.org/abs/2308.03296)” arXiv, 2023.
- George, Thomas, César Laurent, Xavier Bouthillier, Nicolas Ballas, and Pascal Vincent. 2018. “[Fast Approximate Natural Gradient Descent in a Kronecker-Factored Eigenbasis.](https://proceedings.neurips.cc/paper/2018/hash/48000647b315f6f00f913caa757a70b3-Abstract.html)” Neural Information Processing Systems 31 (NeurIPS), 2018.
- Kwon, Yongchan, Eric Wu, Kevin Wu, and James Zou. “[DataInf: Efficiently Estimating Data Influence in LoRA-Tuned LLMs and Diffusion Models.](https://openreview.net/forum?id=9m02ib92Wz)” In The Twelfth International Conference on Learning Representations (ICLR), 2023.


<style>
.video-container {
  position: relative;
  padding-bottom: 56.25%; /* 16:9 aspect ratio */
  height: 0;
  overflow: hidden;
  max-width: 100%;
  background: #000;
}

.video-container iframe {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  border: 0;
}
</style>

<div class="video-container">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/iQavd0dK704" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
